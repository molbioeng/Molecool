{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Database formatting\n",
    "Use this Notebook for initial formatting of the database.\n",
    "\n",
    "Checklist:\n",
    "- Remove patients without ECG signal from data description file (done)\n",
    "- Upload (and format) all ECG signals (done)\n",
    "- Modularise code (done)\n",
    "- Write checks in the functions - should be able to check for errors in metadata and flag this\n",
    "- Ensure all of the metadata information is in a standard form\n",
    "\n",
    "For more information on the pyECG module: \n",
    "https://www.researchgate.net/publication/331012096_PyECG_A_software_tool_for_the_analysis_of_the_QT_interval_in_the_electrocardiogram\n",
    "\n",
    "https://pypi.org/project/pyECG/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyecg import ECGRecord\n",
    "import json\n",
    "import pyarrow.feather as feather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WFDB file formats\n",
    "### Header files\n",
    "The record line\n",
    "E.g. S0250ECG 8 1000 1256376 15:26:59 2006\n",
    "- Record name: S0250ECG\n",
    "- Number of signals: 8\n",
    "- Sampling frequency (in samples per second per signal): 1000\n",
    "- Number of samples per signal: 1256376\n",
    "- Base time (time of day corresponding with the beginning of the record): 15:26:59\n",
    "- Base date: 2006 (this is in the wrong format in the database, a quick fix is just removing it from the header but this may be annoying)\n",
    "\n",
    "Signal specification lines\n",
    "Each of the non-empty, non-comment lines following the record line represent 1 signal.\n",
    "E.g. S0250ECG.dat 16 1(0)/uV 16 0 -88 25184 0 ecg_0\n",
    "- File name (of where the signal is stored): S0250ECG.dat\n",
    "- Format: 16-bit-amplitudes (see documentation on signal files)\n",
    "- ADC gain: 1 (uV)\n",
    "- Baseline: 0 (uV)\n",
    "- ADC resolution (bits): 16\n",
    "- ADC zero: 0\n",
    "- initial value (of signal): -88\n",
    "- checksum (used to verify that the file hasn't been corrupted): 25184\n",
    "- block size: 0\n",
    "- Description: 'ecg_0'\n",
    "\n",
    "For more information on header files: https://archive.physionet.org/physiotools/wag/header-5.htm\n",
    "\n",
    "### Signal files...\n",
    "Info can be found here: https://archive.physionet.org/physiotools/wag/signal-5.htm\n",
    "\n",
    "## Creating Metadata Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting root directory of database to source data from\n",
    "root = 'D:\\Molecool\\Databases\\Database1'\n",
    "droot = 'D:\\Molecool\\og_database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The variables of interest in this database\n",
    "general = ['Group', 'Diabetes Duration','age','BMI','Hb A1C%','CRP (mg/L)','Neuropathy AUTONOMIC SYMPTOMS','WBC K/uL','RBC m/uL','Hgb g/dL','GLUCOSE mg/dL','URINE CREAT mg/dL','URINE ALBUMIN mg/dL', 'CHOLESTmg/dL','LDL CALCmg/dL','Retinopathy Grading']\n",
    "small = ['Group', 'Diabetes Duration','age','BMI','Hb A1C%','CRP (mg/L)','Neuropathy AUTONOMIC SYMPTOMS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the large metadata file\n",
    "# List of patients with ECG readings \n",
    "df_csv = pd.read_csv((droot + '/data_description/GE-75_files_per_subject.csv'), encoding = 'latin-1')\n",
    "df_csv.set_index('Subject ID', inplace=True)\n",
    "df_csv.index = df_csv.index.str.upper() # Patient IDs not uniformly entered\n",
    "df_csv = df_csv.iloc[: , 1:-3] #Drop last 3 columns as well as the group column\n",
    "df_csv = df_csv.loc[(df_csv!=0).any(1)] # Keep patients with data associated\n",
    "\n",
    "# # Create folders for all of the patients with data\n",
    "for sub in df_csv.index:\n",
    "    path = os.path.join(root, sub)\n",
    "    os.mkdir(path)\n",
    "\n",
    "# Importing all other patient variables into a dataframe\n",
    "df_meta = pd.read_csv((droot + '/data_description/GE-75_data_summary_table.csv'), encoding = 'latin-1')\n",
    "df_meta.set_index('patient ID', inplace=True)\n",
    "df_meta.index = df_meta.index.str.upper()\n",
    "df_meta = df_meta[general] #Only taking variables of interest\n",
    "df_meta = pd.concat([df_meta, df_csv], axis=1).reindex(df_csv.index) #Now only use patients with data associated, and...\n",
    "#...combine the two dataframes\n",
    "\n",
    "# # 8 Controls and 46 Diabetics from the 88 initial total\n",
    "# # Now saving this as a new file for future use\n",
    "df_meta.to_json((root + '/LMeta.json'), orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking that data has been saved correctly\n",
    "# Opening JSON file\n",
    "f = open(root + '/formatted_data/LMeta.json')\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "# Iterating through the json\n",
    "# list\n",
    "print(json.dumps(data, indent=4))\n",
    " \n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating and saving small metadata file\n",
    "df_meta = df_meta[small]\n",
    "df_meta.to_json((root + '/SMeta.json'), orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data into feather files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata(header, path):\n",
    "    \"\"\"Create metadata file from the header. Saves total number of samples in the signal and time of the day the signal was started in json file for the patient\"\"\"\n",
    " \n",
    "    f_line = header.readline().split()\n",
    "    if len(f_line) < 5:\n",
    "        d = {'Length of reading':f_line[3], 'Sampling rate': f_line[2], 'Error Flag': False, 'Error Type': 'No error'}\n",
    "    else:\n",
    "        d = {'Length of reading':f_line[3], 'Start time': f_line[4], 'Sampling rate': f_line[2], 'Error Flag': False, 'Error Type': 'No error'}\n",
    "    #os.mkdir(path)\n",
    "    with open((path + '\\\\Meta.json'), \"w\") as outfile:\n",
    "        json.dump(d, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feather(header_path, lead_names, path):\n",
    "    \"\"\"Create Feather file using header file to extract signal from .DAT file\"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    record = ECGRecord.from_wfdb(header_path)\n",
    "    \n",
    "    #Using pyECG Library\n",
    "    for lead in lead_names:\n",
    "        signal = record.get_lead(lead)\n",
    "        df[lead] = pd.Series(signal)\n",
    "            \n",
    "    feather.write_feather(df, (path + '/ECG.ftr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_samples(dpath, ecg_lead_names, folder_name, just_metadata):\n",
    "    \"\"\"Cycle through the files in the folder specified (dpath), create json metadata file...\n",
    "    ...and feather signal file for each. Save these in the folder associated with the patient. \"\"\"\n",
    "    files = sorted(os.listdir(dpath))\n",
    "\n",
    "    for file in files: #Cycle through files in the database\n",
    "        if file.endswith('.hea'):\n",
    "            #Reading and storing the data into structure \n",
    "            hea_path = dpath + file #Change the location of the file or folder.\n",
    "            f = open(hea_path, \"r\")\n",
    "            pat_name = file[:5].upper()\n",
    "            print('Reading data for subject ' + pat_name)\n",
    "            header = open(hea_path, \"r\")\n",
    "            path = root + '\\\\' + pat_name + '\\\\' + folder_name #Patient folder\n",
    "            #os.mkdir(path)\n",
    "            create_metadata(header, path)\n",
    "            if not just_metadata:\n",
    "                create_feather(hea_path, ecg_lead_names, path)\n",
    "\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data for subject S0250\n",
      "Reading data for subject S0256\n",
      "Reading data for subject S0273\n",
      "Reading data for subject S0282\n",
      "Reading data for subject S0283\n",
      "Reading data for subject S0287\n",
      "Reading data for subject S0288\n",
      "Reading data for subject S0292\n",
      "Reading data for subject S0296\n",
      "Reading data for subject S0300\n",
      "Reading data for subject S0301\n",
      "Reading data for subject S0304\n",
      "Reading data for subject S0308\n",
      "Reading data for subject S0310\n",
      "Reading data for subject S0312\n",
      "Reading data for subject S0314\n",
      "Reading data for subject S0315\n",
      "Reading data for subject S0316\n",
      "Reading data for subject S0317\n",
      "Reading data for subject S0318\n",
      "Reading data for subject S0326\n",
      "Reading data for subject S0327\n",
      "Reading data for subject S0339\n",
      "Reading data for subject S0342\n",
      "Reading data for subject S0349\n",
      "Reading data for subject S0365\n",
      "Reading data for subject S0366\n",
      "Reading data for subject S0368\n",
      "Reading data for subject S0372\n",
      "Reading data for subject S0381\n",
      "Reading data for subject S0382\n",
      "Reading data for subject S0390\n",
      "Reading data for subject S0392\n",
      "Reading data for subject S0398\n",
      "Reading data for subject S0403\n",
      "Reading data for subject S0405\n",
      "Reading data for subject S0406\n",
      "Reading data for subject S0409\n",
      "Reading data for subject S0411\n",
      "Reading data for subject S0416\n",
      "Reading data for subject S0420\n",
      "Reading data for subject S0423\n",
      "Reading data for subject S0424\n",
      "Reading data for subject S0426\n",
      "Reading data for subject S0427\n",
      "Reading data for subject S0430\n",
      "Reading data for subject S0432\n",
      "Reading data for subject S0433\n",
      "Reading data for subject S0434\n",
      "Reading data for subject S0435\n",
      "Reading data for subject S0441\n",
      "Reading data for subject S0250\n",
      "Reading data for subject S0254\n",
      "Reading data for subject S0256\n",
      "Reading data for subject S0264\n",
      "Reading data for subject S0273\n",
      "Reading data for subject S0282\n",
      "Reading data for subject S0283\n",
      "Reading data for subject S0287\n",
      "Reading data for subject S0288\n",
      "Reading data for subject S0292\n",
      "Reading data for subject S0296\n",
      "Reading data for subject S0300\n",
      "Reading data for subject S0301\n",
      "Reading data for subject S0304\n",
      "Reading data for subject S0308\n",
      "Reading data for subject S0310\n",
      "Reading data for subject S0312\n",
      "Reading data for subject S0314\n",
      "Reading data for subject S0315\n",
      "Reading data for subject S0316\n",
      "Reading data for subject S0317\n",
      "Reading data for subject S0318\n",
      "Reading data for subject S0326\n",
      "Reading data for subject S0327\n",
      "Reading data for subject S0328\n",
      "Reading data for subject S0339\n",
      "Reading data for subject S0342\n",
      "Reading data for subject S0349\n",
      "Reading data for subject S0365\n",
      "Reading data for subject S0366\n",
      "Reading data for subject S0368\n",
      "Reading data for subject S0372\n",
      "Reading data for subject S0381\n",
      "Reading data for subject S0382\n",
      "Reading data for subject S0390\n",
      "Reading data for subject S0392\n",
      "Reading data for subject S0398\n",
      "Reading data for subject S0403\n",
      "Reading data for subject S0405\n",
      "Reading data for subject S0406\n",
      "Reading data for subject S0409\n",
      "Reading data for subject S0411\n",
      "Reading data for subject S0416\n",
      "Reading data for subject S0420\n",
      "Reading data for subject S0423\n",
      "Reading data for subject S0424\n",
      "Reading data for subject S0426\n",
      "Reading data for subject S0427\n",
      "Reading data for subject S0430\n",
      "Reading data for subject S0432\n",
      "Reading data for subject S0433\n",
      "Reading data for subject S0434\n",
      "Reading data for subject S0250\n",
      "Reading data for subject S0254\n",
      "Reading data for subject S0256\n",
      "Reading data for subject S0264\n",
      "Reading data for subject S0273\n",
      "Reading data for subject S0282\n",
      "Reading data for subject S0287\n",
      "Reading data for subject S0292\n",
      "Reading data for subject S0296\n",
      "Reading data for subject S0300\n",
      "Reading data for subject S0301\n",
      "Reading data for subject S0304\n",
      "Reading data for subject S0312\n",
      "Reading data for subject S0314\n",
      "Reading data for subject S0315\n",
      "Reading data for subject S0316\n",
      "Reading data for subject S0317\n",
      "Reading data for subject S0318\n",
      "Reading data for subject S0326\n",
      "Reading data for subject S0339\n",
      "Reading data for subject S0342\n",
      "Reading data for subject S0349\n",
      "Reading data for subject S0366\n",
      "Reading data for subject S0368\n",
      "Reading data for subject S0372\n",
      "Reading data for subject S0390\n",
      "Reading data for subject S0403\n",
      "Reading data for subject S0405\n",
      "Reading data for subject S0406\n",
      "Reading data for subject S0411\n",
      "Reading data for subject S0416\n",
      "Reading data for subject S0420\n",
      "Reading data for subject S0423\n",
      "Reading data for subject S0424\n",
      "Reading data for subject S0430\n",
      "Reading data for subject S0432\n",
      "Reading data for subject S0433\n",
      "Reading data for subject S0434\n",
      "Reading data for subject S0435\n"
     ]
    }
   ],
   "source": [
    "### Uploading all three ECG sample types ###\n",
    "# Looking at the overnight/12min walking data\n",
    "dpath = droot + \"\\\\ecgdata\\\\\" #Change the location of the file or folder.\n",
    "read_samples(dpath, ['ecg_0','ecg_1'], 'holter', True)\n",
    "\n",
    "# Looking at the head-up-tilt data\n",
    "dpath = droot + \"\\\\labview\\\\converted\\\\head-up-tilt\\\\\" \n",
    "read_samples(dpath, ['ecg'], 'hut', True)\n",
    "\n",
    "# Looking at the head-up-tilt data\n",
    "dpath = droot + \"\\\\labview\\\\converted\\\\sit-to-stand\\\\\" \n",
    "read_samples(dpath, ['ecg'], 'sts', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Length of reading': '1094400', 'Sampling rate': '1000', 'Error Flag': False, 'Error Type': 'No error'}\n"
     ]
    }
   ],
   "source": [
    "#Checking that you can open the JSON file correctly\n",
    "with open('D:\\Molecool\\Databases\\Database1\\S0300\\sts\\Meta.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.068345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.066821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.066528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.064652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.062542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ecg\n",
       "0 -0.068345\n",
       "1 -0.066821\n",
       "2 -0.066528\n",
       "3 -0.064652\n",
       "4 -0.062542"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking that you can open the feather file correctly\n",
    "df = pd.read_feather('D:\\Molecool\\Databases\\Database1\\S0300\\sts\\ECG.ftr')\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
