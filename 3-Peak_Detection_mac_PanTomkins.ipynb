{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "395a482d",
   "metadata": {},
   "source": [
    "# Peak Detection\n",
    "This notebook is made for detecting peaks of the snippets extracted in module 2 using the function defined in x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2321f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pyarrow.feather as feather\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b982e46e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "  \n",
       "\n",
       "  const inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "  \n",
       "\n",
       "  const inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run \"3.0 - Functions_peakdetection.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ffd337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"4.0-HRV_Extraction_Function.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0153bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root = 'G:\\My Drive\\Molecool\\Databases\\Database1'\n",
    "root = '/Volumes/GoogleDrive/.shortcut-targets-by-id/1sZgDE1M3o-bDINfAQYEXl_vqsKs03WxD/Molecool/Databases/Database1' # Jaume's directoru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "caf03e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 56/56 [01:26<00:00,  1.54s/it]\n"
     ]
    }
   ],
   "source": [
    "patients = sorted(os.listdir(root))\n",
    "\n",
    "for pat in tqdm(patients): #Looping throught the folder Sxxxx\n",
    "    if not pat.endswith(('.json', 'ini','\\r')):\n",
    "        path_pat = root+'/'+pat\n",
    "        folders = sorted(os.listdir(path_pat))\n",
    "        for folder in folders:    #Looping through the different ecg types \n",
    "            if not folder.endswith('.ini') and folder != 'Icon\\r':\n",
    "                path_folder = path_pat + '/' +folder   \n",
    "                snippets = sorted(os.listdir(path_folder))\n",
    "                samplingRate = find_rate(path_folder)\n",
    "                for snip_folder in snippets:  #Looping through the snippet folders\n",
    "                    if not snip_folder.endswith(('.json', '.ftr', '.ini','\\r')):\n",
    "                        path_snip =path_folder + '/' + snip_folder\n",
    "                        read_meta(path_snip)\n",
    "                        read_peaks(path_snip, samplingRate)\n",
    "                        read_hrv(path_snip, samplingRate)\n",
    "                        #read_hrv_std(path_snip, samplingRate)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a39cd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_peaks(path,rate):\n",
    "    \"\"\"Function to open snippet files, get peaks, and write them to a new file\"\"\"\n",
    "    df = pd.read_feather(path_snip + '/MSNIP.ftr')   #inputting the ecg feather files in a data frame\n",
    "    df_peaks = _filteringdet(df['ecg_0'],rate)\n",
    "    feather.write_feather(df_peaks, (path_snip + '/PEAKS.ftr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a44ac777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_meta(path):\n",
    "    \"\"\"Function that creates a new meta file for peak files\"\"\"\n",
    "#     with open(path + '\\ManualMeta.json') as json_file:\n",
    "#         metaData = json.load(json_file)\n",
    "#         json_file.close()\n",
    "    data = {'Error Flag': False, 'Error Type': 'No error'}\n",
    "    with open((path + '/PeakMeta.json'), \"w\") as outfile:\n",
    "        json.dump(data, outfile)\n",
    "        outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "371bacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_meta_clean(path,length):\n",
    "    data = {'Error Flag': False, 'Length': length, 'Error Type': 'No error'}\n",
    "    with open((path + '/CleanPeakMeta.json'), \"w\") as outfile:\n",
    "        json.dump(data, outfile)\n",
    "        outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad6fc033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rate(path):\n",
    "    with open(path + '/Meta.json') as json_file:\n",
    "        metaData = json.load(json_file)\n",
    "        json_file.close()\n",
    "        return int(metaData['Sampling rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4acb375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hrv(path,rate):\n",
    "    if path == root + \"/S0250/holter/Snippet001\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        x_values = []\n",
    "        rr_values = []\n",
    "        for index,value in enumerate(df_hrv['x_values']):\n",
    "            if value >= 45000 and value <= 220000:\n",
    "                x_values.append(value)\n",
    "                rr_values.append(df_hrv['R-R Interval Final'][index])\n",
    "        df_clean['R-R Interval Final'] = rr_values\n",
    "        df_clean['x_values'] = x_values\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0273/holter/Snippet000\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        x_values = []\n",
    "        rr_values = []\n",
    "        for index,value in enumerate(df_hrv['x_values']):\n",
    "            if value >= 50000 and value <= 300000:\n",
    "                x_values.append(value)\n",
    "                rr_values.append(df_hrv['R-R Interval Final'][index])\n",
    "        df_clean['R-R Interval Final'] = rr_values\n",
    "        df_clean['x_values'] = x_values\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0273/holter/Snippet002\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        x_values = []\n",
    "        rr_values = []\n",
    "        for index,value in enumerate(df_hrv['x_values']):\n",
    "            if value >= 0 and value <= 250000:\n",
    "                x_values.append(value)\n",
    "                rr_values.append(df_hrv['R-R Interval Final'][index])\n",
    "        df_clean['R-R Interval Final'] = rr_values\n",
    "        df_clean['x_values'] = x_values\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0282/holter/Snippet002\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        x_values = []\n",
    "        rr_values = []\n",
    "        for index,value in enumerate(df_hrv['x_values']):\n",
    "            if value >= 0 and value <= 100500:\n",
    "                x_values.append(value)\n",
    "                rr_values.append(df_hrv['R-R Interval Final'][index])\n",
    "        df_clean['R-R Interval Final'] = rr_values\n",
    "        df_clean['x_values'] = x_values\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0283/holter/Snippet002\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        x_values = []\n",
    "        rr_values = []\n",
    "        for index,value in enumerate(df_hrv['x_values']):\n",
    "            if value >= 50000 and value <= 200000:\n",
    "                x_values.append(value)\n",
    "                rr_values.append(df_hrv['R-R Interval Final'][index])\n",
    "        df_clean['R-R Interval Final'] = rr_values\n",
    "        df_clean['x_values'] = x_values\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0288/holter/Snippet001\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        x_values = []\n",
    "        rr_values = []\n",
    "        for index,value in enumerate(df_hrv['x_values']):\n",
    "            if value >= 20000 and value <= 300000:\n",
    "                x_values.append(value)\n",
    "                rr_values.append(df_hrv['R-R Interval Final'][index])\n",
    "        df_clean['R-R Interval Final'] = rr_values\n",
    "        df_clean['x_values'] = x_values\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0300/holter/Snippet001\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        x_values = []\n",
    "        rr_values = []\n",
    "        for index,value in enumerate(df_hrv['x_values']):\n",
    "            if value >= 100000 and value <= 200400:\n",
    "                x_values.append(value)\n",
    "                rr_values.append(df_hrv['R-R Interval Final'][index])\n",
    "        df_clean['R-R Interval Final'] = rr_values\n",
    "        df_clean['x_values'] = x_values\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0310/holter/Snippet000\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        x_values = []\n",
    "        rr_values = []\n",
    "        for index,value in enumerate(df_hrv['x_values']):\n",
    "            if value >= 100000 and value <= 300000:\n",
    "                x_values.append(value)\n",
    "                rr_values.append(df_hrv['R-R Interval Final'][index])\n",
    "        df_clean['R-R Interval Final'] = rr_values\n",
    "        df_clean['x_values'] = x_values\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0317/holter/Snippet001\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        x_values = []\n",
    "        rr_values = []\n",
    "        for index,value in enumerate(df_hrv['x_values']):\n",
    "            if value >= 50000 and value <= 300000:\n",
    "                x_values.append(value)\n",
    "                rr_values.append(df_hrv['R-R Interval Final'][index])\n",
    "        df_clean['R-R Interval Final'] = rr_values\n",
    "        df_clean['x_values'] = x_values\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0318/holter/Snippet002\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        x_values = []\n",
    "        rr_values = []\n",
    "        for index,value in enumerate(df_hrv['x_values']):\n",
    "            if value >= 0 and value <= 250000:\n",
    "                x_values.append(value)\n",
    "                rr_values.append(df_hrv['R-R Interval Final'][index])\n",
    "        df_clean['R-R Interval Final'] = rr_values\n",
    "        df_clean['x_values'] = x_values\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0366/holter/Snippet002\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        x_values = []\n",
    "        rr_values = []\n",
    "        for index,value in enumerate(df_hrv['x_values']):\n",
    "            if value >= 100000 and value <= 300000:\n",
    "                x_values.append(value)\n",
    "                rr_values.append(df_hrv['R-R Interval Final'][index])\n",
    "        df_clean['R-R Interval Final'] = rr_values\n",
    "        df_clean['x_values'] = x_values\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0372/holter/Snippet000\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        x_values = []\n",
    "        rr_values = []\n",
    "        for index,value in enumerate(df_hrv['x_values']):\n",
    "            if value >= 0 and value <= 250000:\n",
    "                x_values.append(value)\n",
    "                rr_values.append(df_hrv['R-R Interval Final'][index])\n",
    "        df_clean['R-R Interval Final'] = rr_values\n",
    "        df_clean['x_values'] = x_values\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0381/holter/Snippet002\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        x_values = []\n",
    "        rr_values = []\n",
    "        for index,value in enumerate(df_hrv['x_values']):\n",
    "            if value >= 0 and value <= 2300000:\n",
    "                x_values.append(value)\n",
    "                rr_values.append(df_hrv['R-R Interval Final'][index])\n",
    "        df_clean['R-R Interval Final'] = rr_values\n",
    "        df_clean['x_values'] = x_values\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0398/holter/Snippet001\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        x_values = []\n",
    "        rr_values = []\n",
    "        for index,value in enumerate(df_hrv['x_values']):\n",
    "            if value >= 90000 and value <= 200000:\n",
    "                x_values.append(value)\n",
    "                rr_values.append(df_hrv['R-R Interval Final'][index])\n",
    "        df_clean['R-R Interval Final'] = rr_values\n",
    "        df_clean['x_values'] = x_values\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0416/holter/Snippet002\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        x_values = []\n",
    "        rr_values = []\n",
    "        for index,value in enumerate(df_hrv['x_values']):\n",
    "            if value >= 100000 and value <= 300000:\n",
    "                x_values.append(value)\n",
    "                rr_values.append(df_hrv['R-R Interval Final'][index])\n",
    "        df_clean['R-R Interval Final'] = rr_values\n",
    "        df_clean['x_values'] = x_values\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0424/holter/Snippet000\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        x_values = []\n",
    "        rr_values = []\n",
    "        for index,value in enumerate(df_hrv['x_values']):\n",
    "            if value >= 100000 and value <= 300000:\n",
    "                x_values.append(value)\n",
    "                rr_values.append(df_hrv['R-R Interval Final'][index])\n",
    "        df_clean['R-R Interval Final'] = rr_values\n",
    "        df_clean['x_values'] = x_values\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0435/holter/Snippet000\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        x_values = []\n",
    "        rr_values = []\n",
    "        for index,value in enumerate(df_hrv['x_values']):\n",
    "            if value >= 0 and value <= 250000:\n",
    "                x_values.append(value)\n",
    "                rr_values.append(df_hrv['R-R Interval Final'][index])\n",
    "        df_clean['R-R Interval Final'] = rr_values\n",
    "        df_clean['x_values'] = x_values\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0435/holter/Snippet004\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        x_values = []\n",
    "        rr_values = []\n",
    "        for index,value in enumerate(df_hrv['x_values']):\n",
    "            if value >= 25000 and value <= 200000:\n",
    "                x_values.append(value)\n",
    "                rr_values.append(df_hrv['R-R Interval Final'][index])\n",
    "        df_clean['R-R Interval Final'] = rr_values\n",
    "        df_clean['x_values'] = x_values\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0273/holter/Snippet001\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0317/holter/Snippet000\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0326/holter/Snippet000\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0368/holter/Snippet001\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0390/holter/Snippet002\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0409/holter/Snippet000\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0420/holter/Snippet004\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0423/holter/Snippet000\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0423/holter/Snippet002\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0423/holter/Snippet003\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0423/holter/Snippet004\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0426/holter/Snippet002\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0426/holter/Snippet003\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0426/holter/Snippet004\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0427/holter/Snippet001\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0427/holter/Snippet002\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0427/holter/Snippet004\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0430/holter/Snippet003\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0434/holter/Snippet001\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))\n",
    "    if path == root + \"/S0441/holter/Snippet002\":\n",
    "        df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "        df_hrv = RR_calculator(df)\n",
    "        df_clean = pd.DataFrame()\n",
    "        df_clean['R-R Interval Final'] = df_hrv['R-R Interval Final']\n",
    "        df_clean['x_values'] = df_hrv['x_values']\n",
    "        df_clean = _outlier_removal(df_clean)\n",
    "        rr = df_clean['R-R Interval Final'].to_list()\n",
    "        list_end = cos_correction(rr)\n",
    "        df_clean['R-R Interval Final'] = list_end\n",
    "        feather.write_feather(df_clean, (path_snip + '/clean_snippet.ftr'))\n",
    "        read_meta_clean(path,len(df_clean['R-R Interval Final']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5124d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hrv_std(path,rate):\n",
    "    df = pd.read_feather(path_snip + '/PEAKS.ftr')   #inputting the ecg feather files in a data frame\n",
    "    df_hrv = RR_calculator(df)\n",
    "    df_clean = pd.DataFrame()\n",
    "    df_clean['R-R Interval Final'] = cos_correction(df_hrv['R-R Interval Final'])\n",
    "    df_clean['x_values'] = df_hrv['x_values']\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895648b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/79/9_sl0_px0m153y_7w874f1qw0000gn/T/ipykernel_7096/3875875085.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check to see the state of the peaks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpatients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0;31m#Looping throught the folder Sxxxx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ini'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Check to see the state of the peaks\n",
    "count = 0\n",
    "patients = sorted(os.listdir(root))\n",
    "for pat in tqdm(patients):     #Looping throught the folder Sxxxx\n",
    "    if not pat.endswith(('.json', 'ini','\\r')):\n",
    "        path_pat = root+'/'+pat\n",
    "        folders = sorted(os.listdir(path_pat))\n",
    "        for folder in folders:    #Looping through the different ecg types \n",
    "            if not folder.endswith('.ini') and folder != 'Icon\\r':\n",
    "                path_folder = path_pat + '/' +folder   \n",
    "                snippets = sorted(os.listdir(path_folder))\n",
    "                samplingRate = find_rate(path_folder)\n",
    "                for snip_folder in snippets:  #Looping through the snippet folders\n",
    "                    print(\"In snippet folder \" + snip_folder)\n",
    "                    if not snip_folder.endswith(('.json', '.ftr', '.ini','\\r')):\n",
    "                        path_snip =path_folder + '/' + snip_folder\n",
    "                        df = pd.read_feather(path_snip + '/MSNIP.ftr')\n",
    "                        df_signal = df['ecg_0']\n",
    "                        df_peaks = pd.read_feather(path_snip + '/PEAKS.ftr')\n",
    "                        \n",
    "                        y_values = []\n",
    "                        for point in df_peaks['x_values']:\n",
    "                            if point >= 0 and point < 5000:\n",
    "                                y_values.append(df_signal[point])\n",
    "                    \n",
    "                        #print(y_values)\n",
    "                        #print(df_peaks[df_peaks['x_values'] < 5000])\n",
    "\n",
    "                        plt.plot(df_signal[0:5000])\n",
    "                        plt.title('ECG signal ' + pat + snip_folder)\n",
    "                        plt.xlabel('Samples(n)')\n",
    "                        plt.ylabel('Amplitude(mV)')\n",
    "                        plt.scatter(df_peaks[df_peaks['x_values'] < 5000]['x_values'],y_values,marker='o',c='red')\n",
    "                        plt.show()\n",
    "                        \n",
    "                        plt.plot(df_signal)\n",
    "                        plt.title('ECG signal ' + pat + snip_folder)\n",
    "                        plt.xlabel('Samples(n)')\n",
    "                        plt.ylabel('Amplitude(mV)')\n",
    "                        plt.scatter(df_peaks['x_values'],df_peaks['y_values'],marker='o',c='red')\n",
    "                        plt.show()\n",
    "                        count += 1\n",
    "                        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5625ccef",
   "metadata": {},
   "source": [
    "## Checking snippets for accurate peak detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241e915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9536f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_snip = root + \"\\\\S0256\\\\holter\\\\Snippet000\"\n",
    "df = pd.read_feather(path_snip + '/MSNIP.ftr')\n",
    "df_signal = df['ecg_0']\n",
    "df_peaks = pd.read_feather(path_snip + '/PEAKS.ftr')\n",
    "                        \n",
    "                          \n",
    "plt.plot(df_signal)\n",
    "plt.title('ECG signal ')\n",
    "plt.xlabel('Samples(n)')\n",
    "plt.ylabel('Amplitude(mV)')\n",
    "plt.scatter(df_peaks['x_values'],df_peaks['y_values'],marker='o',c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8655b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitely bad snippets\n",
    "badApples = [\"\\\\S0282\\\\holter\\\\Snippet002\",\"\\\\S0296\\\\holter\\\\Snippet000\",\"\\\\S0296\\\\holter\\\\Snippet001\",\"\\\\S0296\\\\holter\\\\Snippet002\",\"\\\\S0366\\\\holter\\\\Snippet001\",\"\\\\S0366\\\\holter\\\\Snippet002\",\"\\\\S0406\\\\holter\\\\Snippet001\",\"\\\\S0406\\\\holter\\\\Snippet002\",\"\\\\S0430\\\\holter\\\\Snippet000\",\"\\\\S0432\\\\holter\\\\Snippet003\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5881d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flagging the snippets with bad peak detection\n",
    "for snip in badApples:\n",
    "    snip_path = root + snip\n",
    "    \n",
    "    data = {'Error Flag': True, 'Error Type': 'Badly detected peaks (through manual inspection)'}\n",
    "        \n",
    "    with open((snip_path + '/PeakMeta.json'), \"w\") as outfile:\n",
    "        json.dump(data, outfile)\n",
    "        outfile.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
